{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173493fa-1f3c-48ab-8fba-5335170b84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from yad2k.models.keras_yolo import yolo_head\n",
    "from yad2k.utils.utils import draw_boxes, get_colors_for_classes, scale_boxes, read_classes, read_anchors, preprocess_image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c53fb9-9759-45d3-ac37-25584f3601c6",
   "metadata": {},
   "source": [
    "### YOLO Box Filtering  \n",
    "Filters predicted bounding boxes based on confidence scores and a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e627b84-51fa-44a7-bd01-8241b2a45650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold=.6):\n",
    "    box_scores = box_confidence * box_class_probs  # Combine confidence and class probabilities\n",
    "    box_classes = tf.argmax(box_scores, axis=-1)  # Get index of highest scoring class\n",
    "    box_class_scores = tf.reduce_max(box_scores, axis=-1)  # Get highest class score\n",
    "    filtering_mask = box_class_scores >= threshold  # Create mask for scores above threshold\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)  # Filter scores\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)  # Filter boxes\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)  # Filter classes\n",
    "    return scores, boxes, classes  # Return filtered results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991a384-e1cc-4bb0-bdba-e00c04f78127",
   "metadata": {},
   "source": [
    "# Intersection over Union (IoU) Calculation  \n",
    "Computes the IoU metric between two bounding boxes (format: x1, y1, x2, y2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22731d24-44c5-445f-a5f3-873afbf2f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1  # Unpack box1 coordinates\n",
    "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2  # Unpack box2 coordinates\n",
    "\n",
    "    xi1 = max(box1_x1, box2_x1)  # Intersection x1 (left)\n",
    "    yi1 = max(box1_y1, box2_y1)  # Intersection y1 (top)\n",
    "    xi2 = min(box1_x2, box2_x2)  # Intersection x2 (right)\n",
    "    yi2 = min(box1_y2, box2_y2)  # Intersection y2 (bottom)\n",
    "    inter_width = max(0, xi2 - xi1)  # Intersection width (0 if no overlap)\n",
    "    inter_height = max(0, yi2 - yi1)  # Intersection height (0 if no overlap)\n",
    "    inter_area = inter_width * inter_height  # Intersection area\n",
    "\n",
    "    box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)  # Area of box1\n",
    "    box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)  # Area of box2\n",
    "    union_area = box1_area + box2_area - inter_area  # Union area\n",
    "\n",
    "    iou = inter_area / union_area if union_area != 0 else 0  # Compute IoU (avoid division by 0)\n",
    "    return iou  # Return Intersection over Union value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73767c-453d-46b2-b261-387d8328146f",
   "metadata": {},
   "source": [
    "### YOLO Non-Max Suppression  \n",
    "Filters overlapping boxes using class-wise NMS and keeps top `max_boxes` predictions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a53896-845f-465a-8359-929a54a0fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes=10, iou_threshold=0.5):\n",
    "    boxes = tf.cast(boxes, dtype=tf.float32)  # Convert boxes to float32\n",
    "    scores = tf.cast(scores, dtype=tf.float32)  # Convert scores to float32\n",
    "\n",
    "    nms_indices = []  # List to store selected indices\n",
    "    classes_labels = tf.unique(classes)[0]  # Get unique class labels\n",
    "    \n",
    "    for label in classes_labels:  # Process each class separately\n",
    "        filtering_mask = classes == label  # Create mask for current class\n",
    "        \n",
    "        boxes_label = tf.boolean_mask(boxes, filtering_mask)  # Filter boxes by class\n",
    "        scores_label = tf.boolean_mask(scores, filtering_mask)  # Filter scores by class\n",
    "        \n",
    "        if tf.shape(scores_label)[0] > 0:  # If any boxes exist for this class\n",
    "            nms_indices_label = tf.image.non_max_suppression(  # Apply NMS\n",
    "                boxes_label,\n",
    "                scores_label,\n",
    "                max_boxes,\n",
    "                iou_threshold=iou_threshold)\n",
    "\n",
    "            selected_indices = tf.squeeze(tf.where(filtering_mask), axis=1)  # Get original indices\n",
    "            nms_indices.append(tf.gather(selected_indices, nms_indices_label))  # Store selected indices\n",
    "\n",
    "    nms_indices = tf.concat(nms_indices, axis=0)  # Combine indices from all classes\n",
    "    \n",
    "    scores = tf.gather(scores, nms_indices)  # Gather selected scores\n",
    "    boxes = tf.gather(boxes, nms_indices)  # Gather selected boxes\n",
    "    classes = tf.gather(classes, nms_indices)  # Gather selected classes\n",
    "    \n",
    "    # Sort by scores and return the top max_boxes\n",
    "    sort_order = tf.argsort(scores, direction='DESCENDING').numpy()  # Get sort order\n",
    "    scores = tf.gather(scores, sort_order[0:max_boxes])  # Keep top scores\n",
    "    boxes = tf.gather(boxes, sort_order[0:max_boxes])  # Keep top boxes\n",
    "    classes = tf.gather(classes, sort_order[0:max_boxes])  # Keep top classes\n",
    "\n",
    "    return scores, boxes, classes  # Return filtered results (fixed typo from 'clases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e2a76b-0948-4102-85bf-5bd6d857edb3",
   "metadata": {},
   "source": [
    "### YOLO Box Coordinates Conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57490b6b-fc04-4729-bbad-b4814d90645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    \"\"\"Convert YOLO box predictions to bounding box corners.\"\"\"\n",
    "    box_mins = box_xy - (box_wh / 2.)  # Calculate bottom-left corner (xmin, ymin)\n",
    "    box_maxes = box_xy + (box_wh / 2.)  # Calculate top-right corner (xmax, ymax)\n",
    "\n",
    "    return tf.keras.backend.concatenate([\n",
    "        box_mins[..., 1:2],  # y_min\n",
    "        box_mins[..., 0:1],  # x_min\n",
    "        box_maxes[..., 1:2],  # y_max\n",
    "        box_maxes[..., 0:1]  # x_max\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81c2cc-2085-4a55-ba02-89df2d0f8104",
   "metadata": {},
   "source": [
    "###  YOLO Output Evaluation Processes raw YOLO model outputs into final detections with filtering and NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633bad37-8284-4f47-be60-0bf0a71ce6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape = (720, 1280), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
    "    \n",
    "    \n",
    "    \n",
    "   # Retrieve outputs of the YOLO model\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = yolo_outputs\n",
    "\n",
    "    # Convert boxes to be ready for filtering functions (convert boxes box_xy and box_wh to corner coordinates)\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "\n",
    "    # Perform Score-filtering with a threshold of score_threshold\n",
    "    scores, boxes, classes = yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold=score_threshold)\n",
    "\n",
    "    # Scale boxes back to original image shape\n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "\n",
    "    # Perform Non-max suppression with maximum number of boxes set to max_boxes and a threshold of iou_threshold\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes=max_boxes, iou_threshold=iou_threshold)\n",
    "   \n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb4173-3b43-4c74-b4c1-ae4974898dce",
   "metadata": {},
   "source": [
    "### YOLO Model Initialization  \n",
    "Loads class names, anchor boxes, and pre-trained YOLO model for object detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87546272-753e-424e-a6bb-8bf964ab3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model configuration files and initialize model\n",
    "class_names = read_classes(\"model_data/coco_classes.txt\")  # Load 80 COCO class names (person, car, etc.)\n",
    "anchors = read_anchors(\"model_data/yolo_anchors.txt\")  # Load 9 YOLO anchor boxes (predefined bounding box shapes)\n",
    "model_image_size = (608, 608)  # Input image dimensions required by YOLO network\n",
    "\n",
    "# Load pre-trained YOLO model (without compilation since we're using it for inference)\n",
    "yolo_model = load_model(\"model_data/\", compile=False)  # Original weights trained on COCO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236eb928-1717-4093-975f-7a8cf679bfae",
   "metadata": {},
   "source": [
    "### YOLO Object Detection Prediction\n",
    "Performs end-to-end object detection on an input image using YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59330d7b-bd34-47b1-a218-b3274ad9c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_file):\n",
    "    # Preprocess your image\n",
    "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
    "    \n",
    "    yolo_model_outputs = yolo_model(image_data)\n",
    "    yolo_outputs = yolo_head(yolo_model_outputs, anchors, len(class_names))\n",
    "    \n",
    "    out_scores, out_boxes, out_classes = yolo_eval(yolo_outputs, [image.size[1],  image.size[0]], 10, 0.3, 0.5)\n",
    "\n",
    "    # Print predictions info\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), \"images/\" + image_file))\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    colors = get_colors_for_classes(len(class_names))\n",
    "    # Draw bounding boxes on the image file\n",
    "    #draw_boxes2(image, out_scores, out_boxes, out_classes, class_names, colors, image_shape)\n",
    "    draw_boxes(image, out_boxes, out_classes, class_names, out_scores)\n",
    "    # Save the predicted bounding box on the image\n",
    "    image.save(os.path.join(\"out\", image_file), quality=100)\n",
    "    # Display the results in the notebook\n",
    "    output_image = Image.open(os.path.join(\"out\", image_file))\n",
    "    imshow(output_image)\n",
    "\n",
    "    return out_scores, out_boxes, out_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16d8445-29d9-4071-8d80-8ff7d639dd7b",
   "metadata": {},
   "source": [
    "### Run YOLO Object Detection\n",
    "Detects objects in 'test.jpg' and returns bounding boxes, scores, and class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78a8c5-889c-434a-a724-f77879cb238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test image\n",
    "out_scores, out_boxes, out_classes = predict(\"test.jpg\")\n",
    "\n",
    "# Output will contain:\n",
    "# - out_scores: Confidence scores for each detection (0-1)\n",
    "# - out_boxes: Bounding box coordinates [y1, x1, y2, x2] in original image scale\n",
    "# - out_classes: Class indices corresponding to class_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
